# Dise√±o del DAaaS

## Definici√≥n de la estrategia del DAaaS üèóÔ∏è

Se desarrollar√° una p√°gina web para uso exclusivo y privado de una compa√±√≠a, con el prop√≥sito de clasificar videojuegos. Esta clasificaci√≥n se llevar√° a cabo considerando criterios de popularidad y precio. La finalidad de esta plataforma es identificar los art√≠culos de cada categor√≠a ‚Äì por ejemplo: Xbox, Nintendo, PlayStation, entre otros ‚Äì que presenten una alta demanda y rentabilidad, con el objetivo de importarlos a Latinoam√©rica para su posterior comercializaci√≥n.

La plataforma le permitir√° a la compa√±√≠a acceder a informaci√≥n relevante sobre los art√≠culos, incluyendo: (i) identificaci√≥n del art√≠culo con base en la regi√≥n, a saber: Estados Unidos, Europa y Jap√≥n; (ii) estado de conservaci√≥n; (iii) precios de venta; y (iv) las valoraciones cuantitativas de los usuarios y prensa especializada. A continuaci√≥n se detalla la forma como se visualizar√° la informaci√≥n:

* ID, Image, Title, Console: Identificaci√≥n del videojuego por su imagen, nombre, consola/regi√≥n.  
*	Loose Price: Precio del cartucho o disco del juego por s√≠ solo, no incluye otros elementos.
*	Complete Price (CIB): Precio del juego completo en caja. El cartucho o disco se incluye con la caja original y el manual de instrucciones original.
*	Brand New Price: Precio del juego, la caja y el manual est√°n incluidos y est√°n en su pl√°stico original sellado de f√°brica.
*	Graded Price: Precio del art√≠culo nuevo que ha sido calificado por una agencia de calificaci√≥n de condiciones como VGA o CGC Games.
*	MetaScore y UserScore: Valoraciones cuantitativas promedio de prensa especializada y usuarios.  

Adicionalmente, se realizar√° el procesamiento de la informaci√≥n de ventas promedio de los art√≠culos en tiendas en l√≠nea de Latinoam√©rica, como MercadoLibre, para realizar comparativas de precios. Se aplicar√° un tratamiento de datos para representar de manera precisa la oferta en LATAM en este segmento.

De esta manera, la compa√±√≠a tendr√° la capacidad de analizar individualmente cada art√≠culo, lo que permitir√° un an√°lisis comparativo m√°s detallado basado en el valor promedio de venta de los art√≠culos a importar. Tambi√©n podr√°n marcar productos de inter√©s o agregarlos directamente a la lista de art√≠culos a importar.

La informaci√≥n anteriormente descrita se mostrar√° en una tabla de calificaci√≥n con la siguiente estructura:


![image](https://github.com/pardo2410/BigDataArchitecture/assets/10873597/e704e4c1-04e8-4868-82dd-4b971ad5b423)


Adem√°s, se dise√±ar√° una tabla detallada de art√≠culos la cual permitir√° visualizar el historial de precios del articulo a lo largo del tiempo. Esta herramienta ser√° valiosa para identificar tendencias de valor y fluctuaciones de precios. A continuaci√≥n, se muestra la estructura de la tabla detallada por art√≠culo: 

![image](https://github.com/pardo2410/BigDataArchitecture/assets/10873597/7a03c07d-5650-48a0-8b33-ca56161bfe1a)


Es importante mencionar que el dashboard se actualizar√° autom√°ticamente de forma semanal para teniendo en cuenta la estabilidad de los precios en este segmento. 

A medida que la p√°gina web se desarrolle y expanda para satisfacer las necesidades de la empresa, se tienen previstas funcionalidades adicionales, que incluyen:

*	Integraci√≥n con plataformas de subastas: Esto permitir√° a los usuarios rastrear y participar en subastas en l√≠nea de art√≠culos coleccionables, adem√°s de proporcionar informaci√≥n en tiempo real sobre el estado de las subastas.
*	Comunidad y foros: Se conformar√° una comunidad en l√≠nea donde los coleccionistas podr√°n discutir, intercambiar informaci√≥n y compartir consejos sobre art√≠culos espec√≠ficos y tendencias en el mercado.
*	Herramientas de an√°lisis avanzado: Se ofrecer√°n herramientas anal√≠ticas avanzadas que permitir√°n a los usuarios realizar an√°lisis detallados de datos, como correlaciones entre diferentes factores y pron√≥sticos de precios.
*	Gesti√≥n de Inventarios: Se proporcionar√°n herramientas para que los usuarios puedan llevar un registro de su inventario de art√≠culos a importar, gestionando cantidades y condiciones.

## Arquitectura DAaaS üìö

*	Web page.
*	Base de datos Google Cloud SQL.
*	Crawler mediante Cloud Functions para obtener la informaci√≥n relacionada con valoraciones de prensa (MetaScore) y usuarios (User Score) directamente a la URL de Metacritic.
*	Crawler mediante Cloud Functions para obtener la informaci√≥n del precio de venta de los art√≠culos a analizar a trav√©s de la API de MercadoLibre y c√°lculo del precio promedio por art√≠culo.  
*	Scrapping mediante Cloud Functions para extraer la informaci√≥n de la URL de PriceCharting (Image, Console, Title, Losse Price, Complete Price, New Price, Grade Price).
*	Se utilizar√° Cloud Functions para efectuar las consultas a los diferentes csv con el fin de generar los reportes que posteriormente consultar√° el usuario.
*	Implementaci√≥n de Cloud Schedeler para actualizar los registros de los datos de manera semanal.

## DAaaS Operating Model Design and Rollout üìÉ 

El primer paso ser√° implementar web Scraping en Python, utilizando las bibliotecas Selenium y BeautifulSoup (BS4), con el fin de extraer informaci√≥n de la URL de PriceCharting. La informaci√≥n a extraer incluye: Image, Title, Console, Losse Price, Complete Price, New Price, Grade Price. Esta informaci√≥n ser√° almacenada en un archivo en formato .csv en una base de datos relacional Google SQL.

El siguiente paso ser√° extraer la informaci√≥n de Metacritic, que incluye el MetaScore y el User Score, para esto es necesario realizar un web Crawler en Python utilizando la biblioteca Scrapy. Este proceso generar√° una lista de art√≠culos con las puntuaciones promedio de los usuarios y de la prensa especializada, y crear√° un archivo .csv que se almacenar√° en Google SQL.

A continuaci√≥n, se llevar√° a cabo un segundo web Crawler en Python, empleando las bibliotecas Requests y BS4, con el objetivo de extraer informaci√≥n vinculada a los art√≠culos y sus precios de venta desde la p√°gina de MercadoLibre. Asimismo, se realizar√° el c√°lculo del valor promedio por articulo utilizando Cloud Function y el resultado se guardar√° en un archivo .csv que ser√° almacenado en Google SQL.

Por √∫ltimo, se generan la tabla de clasificaci√≥n y las tablas detalladas por art√≠culo utilizando Cloud Functions para crear los informes que se almacenar√°n posteriormente en Google SQL. Estos informes podr√°n ser consultados por el usuario final. Este proceso se actualizar√° semanalmente mediante la implementaci√≥n de Cloud Scheduler. 


## Diagrama üõ†Ô∏è

![image](https://github.com/pardo2410/BigDataArchitecture/assets/10873597/900fb3a6-746d-4bee-ac42-25e0611de763)


